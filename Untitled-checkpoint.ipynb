{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "193.892px",
        "left": "897.472px",
        "right": "20px",
        "top": "117.989px",
        "width": "302.344px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "__version__tensorflow",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Mon Apr  6 13:54:17 2020\n\n@author: Taehan Kim, Seunghyun Jang\n\"\"\"\n\nimport glob #file directory\nimport shutil\nimport os\nimport random\nfrom PIL import Image\nimport seaborn as sns #statistical data visualization\nimport pandas as pd\nimport pandas.util.testing as tm\nimport numpy as np\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom tensorflow.keras.layers import Dense, Input, Activation, Flatten\nfrom tensorflow.keras.layers import BatchNormalization,Add,Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import LeakyReLU, ReLU, Conv2D, MaxPooling2D, BatchNormalization, Conv2DTranspose, UpSampling2D, concatenate\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras import backend as K",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  from ipykernel import kernelapp as app\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "C:\\ProgramData\\Anaconda3\\envs\\xogks5479\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "#%% mask_df는 정답 마스크에 대해 정의 하고 이를 정리해놓은 변수\nmask_filenames = glob.glob('C:/Users\\김태한/Desktop/연구실/All in Focus/goblet_cell/masks/*')\nmask_df = pd.DataFrame()\nmask_df['filename'] = mask_filenames\nmask_df['mask_percentage'] = 0\nmask_df['labels'] = 0\nmask_df.set_index('filename', inplace=True)\n\nfor file in mask_filenames:\n    mask_df.loc[file, 'mask_percentage'] = np.array(Image.open(file)).sum()/(128*128)\n\nmask_df.loc[mask_df.mask_percentage > 0, 'labels'] = 1\n#%% \ntrain_valid_filenames = glob.glob('C:/Users/김태한/Desktop/연구실/All in Focus/goblet_cell/train/*')\n#전부 마스크에 대한 변수가 됩니다. \ntrain_filenames, valid_filenames = train_test_split(train_valid_filenames, stratify = mask_df.labels, test_size = 0.2, random_state = 10)\nmask_train_filenames = [f.replace('/train', '/masks') for f in train_filenames]\nmask_valid_filenames = [f.replace('/train', '/masks') for f in valid_filenames]\n# from efficientnet import EfficientNetB0",
      "metadata": {},
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "#%%\ntrain_x = np.zeros((len(train_filenames),128,128))\nvalid_x = np.zeros((len(valid_filenames),128,128))\ntrain_mask_y = np.zeros((len(train_filenames),128,128))\nvalid_mask_y = np.zeros((len(valid_filenames),128,128))\ntrain_y = np.zeros((len(train_filenames)))\nvalid_y = np.zeros((len(valid_filenames)))\n\n# 훈련용 .train image\nfor (index, image) in enumerate(train_filenames[:]): #index와 내용을 함께\n    train_x[index] = np.array(Image.open(image))\n    \n# 검증용 및 변병여부 .train image\nfor (index, image) in enumerate(valid_filenames[:]):\n    valid_x[index] = np.array(Image.open(image))\n    \n# 훈련용 마스크 답지 및 병변여부 .mask image\nfor (index, image) in enumerate(mask_train_filenames[:]):\n    train_mask_y[index] = np.array(Image.open(image))\n    train_y[index] = mask_df.loc[image, 'labels']\n    \n# 검증용 병변 답지 및 병변여부 .mask image\nfor (index, image) in enumerate(mask_valid_filenames[:]):\n    valid_mask_y[index] = np.array(Image.open(image))\n    valid_y[index] = mask_df.loc[image, 'labels']",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train_x = train_x.reshape(len(train_filenames),128,128,1)\nvalid_x = valid_x.reshape(len(valid_filenames),128,128,1)\n\ntrain_mask_y = train_x.reshape(len(train_filenames),128,128,1)\nvalid_mask_y = valid_x.reshape(len(valid_filenames),128,128,1)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def UNet(pretrained_weights = None,input_size = (128,128,1)):\n    inp = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inp)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    \n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    \n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    \n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    drop4 = Dropout(0.2)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    drop5 = Dropout(0.2)(conv5)\n\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n\n    model = Model(inputs = inp, outputs=[conv10])\n\n    return model",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_loss_core(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n    iou = (intersection + smooth) / ( union + smooth)\n    return iou\n\n\nmodel = UNet()\nmodel.summary()\nmodel.compile(optimizer = Adam(lr = 1e-3), loss = iou_loss_core, metrics = [dice_coef])",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "history = model.fit(train_x/65535, [train_mask_y/65535],\n                                    epochs = 10, \n                                    batch_size = 128,\n                                    verbose = 1, \n                                    validation_data=(valid_x/65535,[valid_mask_y/65535]))",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}